{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://blog.christianperone.com/2013/09/machine-learning-cosine-similarity-for-vector-space-models-part-iii/\n",
    "# https://stackoverflow.com/questions/8897593/similarity-between-two-text-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF \n",
    "\n",
    "tf-idf, short for term frequency–inverse document frequency, is a numeric measure that is use to score the importance of a word in a document based on how often did it appear in that document and a given collection of documents. The intuition for this measure is : If a word appears frequently in a document, then it should be important and we should give that word a high score. But if a word appears in too many other documents, it’s probably not a unique identifier, therefore we should assign a lower score to that word. \n",
    "\n",
    "See [https://ethen8181.github.io/machine-learning/clustering_old/tf_idf/tf_idf.html](https://ethen8181.github.io/machine-learning/clustering_old/tf_idf/tf_idf.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size tfidf matrix (#documents, #unique words): (4, 11)\n",
      "unique words ['blue', 'bright', 'can', 'in', 'is', 'see', 'shining', 'sky', 'sun', 'the', 'we']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "documents = (\n",
    "\"The sky is blue\",\n",
    "\"The sun is bright\",\n",
    "\"The sun in the sky is bright\",\n",
    "\"We can see the shining sun, the bright sun\"\n",
    ")\n",
    "\n",
    "tfidf = vectorizer.fit_transform(documents)\n",
    "print ('size tfidf matrix (#documents, #unique words):', tfidf.shape)\n",
    "\n",
    "print('unique words', vectorizer.get_feature_names() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9)\t0.3439932714296342\n",
      "  (0, 7)\t0.5197138488789809\n",
      "  (0, 4)\t0.42075315164463567\n",
      "  (0, 0)\t0.6591911178676787\n",
      "  (1, 9)\t0.42685800978431027\n",
      "  (1, 4)\t0.5221086219944969\n",
      "  (1, 8)\t0.5221086219944969\n",
      "  (1, 1)\t0.5221086219944969\n",
      "  (2, 9)\t0.5262610401109715\n",
      "  (2, 7)\t0.3975443320946988\n",
      "  (2, 4)\t0.32184639875982174\n",
      "  (2, 8)\t0.32184639875982174\n",
      "  (2, 1)\t0.32184639875982174\n",
      "  (2, 3)\t0.5042345768555538\n",
      "  (3, 9)\t0.39096308821336656\n",
      "  (3, 8)\t0.4782039801500678\n",
      "  (3, 1)\t0.2391019900750339\n",
      "  (3, 10)\t0.37459947122408604\n",
      "  (3, 2)\t0.37459947122408604\n",
      "  (3, 5)\t0.37459947122408604\n",
      "  (3, 6)\t0.37459947122408604\n"
     ]
    }
   ],
   "source": [
    "# Inspect the tfidf matrix\n",
    "print(tfidf_matrix)\n",
    "# 'shining' is element 6; it appears only in last document (index 3)\n",
    "# (3,6) is set, (0,6), (1,6), (2,6) are not set\n",
    "# 'sun' (element 8) does not appear in doc 0 (0, 8) missing\n",
    "# once in doc 1 and doc 2 (but doc 1 is shorter, so 0.52 (cell 1,8) is larger than 0.32 (cell 2,8)\n",
    "# appears twice in doc 3, but doc 3 is longer, 0.47 (cell 3,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix\n",
      " [[1.         0.36651513 0.52305744 0.13448867]\n",
      " [0.36651513 1.         0.72875508 0.54139736]\n",
      " [0.52305744 0.72875508 1.         0.43661098]\n",
      " [0.13448867 0.54139736 0.43661098 1.        ]]\n",
      "\n",
      "cells\n",
      "   (0, 3)\t0.13448867172274862\n",
      "  (0, 2)\t0.5230574383703659\n",
      "  (0, 1)\t0.36651513142667\n",
      "  (0, 0)\t0.9999999999999998\n",
      "  (1, 3)\t0.5413973573965388\n",
      "  (1, 2)\t0.728755079459936\n",
      "  (1, 1)\t0.9999999999999998\n",
      "  (1, 0)\t0.36651513142667\n",
      "  (2, 3)\t0.4366109847740327\n",
      "  (2, 2)\t0.9999999999999998\n",
      "  (2, 1)\t0.728755079459936\n",
      "  (2, 0)\t0.5230574383703659\n",
      "  (3, 3)\t1.0\n",
      "  (3, 2)\t0.4366109847740327\n",
      "  (3, 1)\t0.5413973573965388\n",
      "  (3, 0)\t0.13448867172274862\n"
     ]
    }
   ],
   "source": [
    "# get tf-idf matrix\n",
    "pairwise_similarity = (tfidf * tfidf.T)\n",
    "# .A shows it as a matrix\n",
    "print('matrix\\n', pairwise_similarity.A)\n",
    "print('\\ncells\\n', pairwise_similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
