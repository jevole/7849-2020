{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full text search on WRDS SEC Analytics Suite\n",
    "\n",
    "Link: [WRDS SEC Analytics Suite](https://wrds-web.wharton.upenn.edu/wrds/ds/sec/search/fsearch.cfm?navId=359)\n",
    "    \n",
    "Search for: tax\n",
    "    \n",
    "In: Correspondence\n",
    "    \n",
    "Period: Jan 2016 - Jan 2018\n",
    "\n",
    "4,629 results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results (csv) and download these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '000157/1571371/0001104659-17-053266.txt',\n",
       "  'conformed_submission_type': 'CORRESP',\n",
       "  'filer_central_index_key': '0001571371',\n",
       "  'filer_former_company_former_conformed_name': '',\n",
       "  'filer_company_conformed_name': 'Summit Materials, LLC',\n",
       "  'accession_number': '0001104659-17-053266',\n",
       "  'filed_as_of_date': '2017-08-23 00:00:00+00:00',\n",
       "  'conformed_period_of_report': '2017-12-27 00:00:00+00:00'},\n",
       " {'id': '000162/1621563/0001104659-17-053266.txt',\n",
       "  'conformed_submission_type': 'CORRESP',\n",
       "  'filer_central_index_key': '0001621563',\n",
       "  'filer_former_company_former_conformed_name': '',\n",
       "  'filer_company_conformed_name': 'Summit Materials, Inc.',\n",
       "  'accession_number': '0001104659-17-053266',\n",
       "  'filed_as_of_date': '2017-08-23 00:00:00+00:00',\n",
       "  'conformed_period_of_report': '2017-12-27 00:00:00+00:00'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "from random import *\n",
    "\n",
    "# make list of dictionaries\n",
    "with open('WRDS_SEC_search_tax_in_comment_letters.csv') as f:\n",
    "    letters = [{k: v for k, v in row.items()} for row in csv.DictReader(f, skipinitialspace=True)]\n",
    "\n",
    "letters[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: 000088/880417/0000906318-03-000077.txt\n",
    "# needs to become: https://www.sec.gov/Archives/edgar/data/880417/000090631803000077/0000906318-03-000077.txt\n",
    "# this function turns the 'shortened' url into the actual url that can be accessed\n",
    "def idToUrl( url ):\n",
    "    # cut the url in three pieces (e.g. '000088' ,'880417', and '0000906318-03-000077.txt')\n",
    "    urlPieces = url.split('/')\t\n",
    "    # we need to make a piece that is like the last piece, but without '-' and have '.txt' removed\n",
    "    midpiece = urlPieces[2].replace(\"-\", \"\")[:-4]\n",
    "    # glue the pieces together\n",
    "    fullUrl  = 'https://www.sec.gov/Archives/edgar/data/' + urlPieces[1] + '/' + midpiece + '/' + urlPieces[2]\n",
    "    return (fullUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.sec.gov/Archives/edgar/data/1571371/000110465917053266/0001104659-17-053266.txt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idToUrl('000157/1571371/0001104659-17-053266.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time\n",
    "\n",
    "myCounter = 0\n",
    "\n",
    "for letter in letters[0:20]:    \n",
    "    myCounter += 1\n",
    "    # get filing\n",
    "    r = requests.get(  idToUrl ( letter['id'])  )\n",
    "    # write to file\n",
    "    with open('letters/' + str(myCounter) + '.html', 'wb') as f:\n",
    "        f.write( r.content )\n",
    "    # sleep 1 second\n",
    "    time.sleep(1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert HTML files to text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('letters/1.html') as f:\n",
    "    content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab <DOCUMENT>.. <TEXT> through </TEXT>\n",
    "import re\n",
    "doc = re.findall(\"<DOCUMENT>.*?<TEXT>(.*?)<\\/TEXT>\", content, flags=re.DOTALL)  \n",
    "doc[0][0:100]\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "# need to do: pip install w3lib\n",
    "from w3lib.html import replace_entities\n",
    "# functions that converts html to text\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return replace_entities(cleantext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\xa0\\n\\n\\n\\n    \\n\\n1550   Wynkoop Street, 3rd\\xa0Fl   Denver, Colorado 80202\\n\\xa0\\n(303)   893-0012 Office    (303) 893-6993 Fax       \\n\\n\\nsummit-materials.com         \\n\\xa0\\nVIA COURIER AND EDGAR\\n\\xa0\\n\\n\\n\\n\\xa0    \\n\\nAugust\\xa023, 2017         \\n\\xa0\\nRe:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Summit Materials,\\xa0Inc.\\nSummit Materials, LLC\\nForm\\xa010-K for Fiscal Year Ended December\\xa031, 2016\\nFiled February\\xa028, 2017\\nFile No.\\xa01-36873\\nFile No.\\xa0333-187556\\n\\xa0\\nTerence Oâ€™Brien\\nAccounting Branch Chief\\nOffice of Manufacturing and Construction\\nSecuriti'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = cleanhtml( doc[0])\n",
    "text[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 letters\\1.html 124125\n",
      "10 letters\\10.html 30881\n",
      "11 letters\\11.html 17513\n",
      "12 letters\\12.html 14447\n",
      "13 letters\\13.html 36022\n",
      "14 letters\\14.html 34407\n",
      "15 letters\\15.html 33780\n",
      "16 letters\\16.html 18504\n",
      "17 letters\\17.html 724508\n",
      "18 letters\\18.html 724508\n",
      "19 letters\\19.html 55372\n",
      "2 letters\\2.html 124125\n",
      "20 letters\\20.html 43204\n",
      "3 letters\\3.html 75337\n",
      "4 letters\\4.html 44726\n",
      "5 letters\\5.html 45138\n",
      "6 letters\\6.html 33895\n",
      "7 letters\\7.html 64519\n",
      "8 letters\\8.html 75865\n",
      "9 letters\\9.html 18183\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "# files holds a list with elements each being a path to a html file\n",
    "files = glob.glob('letters/*.html')\n",
    "\n",
    "for file in files:\n",
    "    # grab the counter (1, 2, ...) that is part of the path (e.g. 20 in letters\\20.html )\n",
    "    myCounter = re.findall(r'(\\d*)\\.html', file)[0]\t    \n",
    "    # read the file\n",
    "    with open( file) as f:\n",
    "        content = f.read()\n",
    "    # grab first document (exhibits are separate documents)\n",
    "    doc = re.findall(\"<DOCUMENT>.*?<TEXT>(.*?)<\\/TEXT>\", content, flags=re.DOTALL)\n",
    "    if (len(doc)) >= 1:\n",
    "        # clean up\n",
    "        text = cleanhtml( doc[0] )    \n",
    "        # write to disk    \n",
    "        with open('letters_text/' + str(myCounter) + '.txt', 'w', encoding=\"utf-8\") as f:\n",
    "            f.write( text )     \n",
    "        # all good\n",
    "        print(myCounter, file, len(content))\n",
    "    else:\n",
    "        print('Could not find TEXT in file ', file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEC Master Archive\n",
    "\n",
    "Link: [http://www.wrds.us/index.php/repository/view/25](http://www.wrds.us/index.php/repository/view/25)\n",
    "    \n",
    "The filing dataset holds CIK, filing date, form type (10-K, 8-K, etc) and url. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
